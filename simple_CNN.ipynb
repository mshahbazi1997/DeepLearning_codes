{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple code\n",
    "First make sure that you install requirements:\n",
    "\n",
    "`!pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flZ1MOT8F8kE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder # this function is used to prepare one-hot encoded labels\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10,3) # set default size of plots\n",
    "\n",
    "data_dir = os.path.join(os.path.expanduser('~'),'Documents','Data')\n",
    "save_dir = os.path.join(os.path.expanduser('~'),'Documents','Data','Simulations')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rg-CYaG9GU03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAEUCAYAAADuhRlEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApUklEQVR4nO3de3DU5dk38O+eDzns5kBOJIGAEFEOWhSMWItCien7OB54+qrttNg62trgO0o7Vmas1rbPxMOMh7YUZloLdd5SrH1FH7HFYpRQHwmWFIqohIMBgskGCGw22ex57/cPypaYve6w8MMc/H5mdgb22t3fvb/dXNnsdd/XbVJKKRARGcg83AMgorGHiYWIDMfEQkSGY2IhIsMxsRCR4ZhYiMhwTCxEZDgmFiIyHBMLERnOOtwD+LRkMomOjg7k5OTAZDIN93CI6F+UUujt7UVZWRnM5iE+k6gL5Je//KWaMGGCcjgcas6cOWrbtm1ndb/29nYFgBdeeBmhl/b29iF/ji/IJ5YXX3wRy5Ytw6pVqzB37lw8++yzqK2tRWtrK4qKirT3zcnJAQA88fxaON3uQfGOvTvF+x4/1Kp97ERCfrpF5VPFWHlVtRjzFpdrj+l0ycfc/9E2MXb4491iLN4XFGMWzXMEgBxvrhizOgaf79NmX3W1GJt0kXzuwoGT2vF89OEuMZZMRsVYLB4WY3s++lB7zN6ebjEWiUbEWDxmEWMnT4TEWF+/PFYAiCfk51lYmCfGvHlZYiyp+vTHjMuxcEilvT4Wi2PTG1tSP6M6FySxPP3007j77rvxrW99CwCwatUqvP766/jtb3+Lhx56SHvf03/+ON1uuNyDT5zD6RTva7fbtY+tSyy6x3WlSXCnubOytcfUJRanyyWPx+EQY+ZoTIwNlVh0j2t1yjF3lvwmzta80axJeawA4HbL5yCZlH+QozH5z2SHQ/8+iNhtYkwhKcZMkMdjtcrP02od4sfMlBBDNpt8X7vmeSSG+Myg+5YhEU+fWP5936G/ojD8y9toNIqWlhYsXLjw3wcxm7Fw4UJs3bp10O0jkQgCgcCACxGNboYnluPHjyORSKC4uHjA9cXFxfD5fINu39DQAI/Hk7pUVFQYPSQi+owNe7l5+fLl6OnpSV3a29uHe0hEdJ4M/46lsLAQFosFXV1dA67v6upCSUnJoNs7HA7t3/1ENPoYnljsdjtmz56NxsZG3HzzzQBOzU1pbGzE0qVLz/pxev0nEYsM/oa+wJsv3keNKxZjAKCsckWktHKSGEtovoA0J/u1x0z2y1+/h0/K1QkVkisJ4wvlylplxUXa8VRcNEGMlY2XK1xFRfK5tdnkXwxxr/zFNwBUlA/+ZZO6b1yuloTDchXGf1JfETl+/IQYs9rlL/Fhkr+8zSuQz4EzSx4rAPRoKmcOp/wjmlTye8tm1f+yDvT4xVg0kv7L23hMU0r6lAtSFVq2bBmWLFmCK664AnPmzMGzzz6LYDCYqhIR0dh2QRLLbbfdhmPHjuGRRx6Bz+fDZZddho0bNw76QpeIxqYLNqV/6dKlGf3pQ0Rjx7BXhYho7GFiISLDMbEQkeFGXNuElFgMSLP+IhqRS7/9/XJ5EgAmTh0vxvqC8sK+aEwu/eYXerTHtNrk3D1lirx47+qrrhBj4zULHz2ecdrxxKzyuhS3Zq2QVbN8xKRZ0RYK6ku/kZj8erpdcqk6zyuX3CdPukR7zI8+0ixWNcnjiUTkqQWeXHmxoE2/dAk9gS4xpiC/p5NJ+UU5eVJ+PwNAqF9ebCltYRhPnH25mZ9YiMhwTCxEZDgmFiIyHBMLERmOiYWIDMfEQkSGY2IhIsON2Hks8XAY8TS9NU1xeR6Gwy73TwWAnuPHxVhBiTw3pPJSuRVBUUWZ9pg23SSGuDxnQtssulNut9D/8THteGJmeV5E6/v/FGNXTpPnhlw750oxpqRJEf8SCPSIscOHOsSY3abrfSy3xwCAwnHyfKbD7fvkx3XK82r6QvK8kUBAft8BgNUm95DNzZWPGQrJ82qGmnISj8u9fcWewfqXcgB+YiEiwzGxEJHhmFiIyHBMLERkOCYWIjIcEwsRGW7ElpsjoX6Y1OCSWLZLLjPm5utbBnxh1mVirGLSFDHWq2kL0Pqxfh+kQL9cEuzz+8VYt18uKXf65K7uuUO0TYBZXi6/4cX/J8Zs/1v+HfSlmmvk+9n0W6yWlGjK9Uou0/pP9oqxf+yQ94MGAKtmV4GsHLlUHU/I9dZon1+MWYb49T1unLzzREKzr3P3Cfn8mKHfHUG37avXm74VSEzT4mLw8YmIDMbEQkSGY2IhIsMxsRCR4ZhYiMhwTCxEZDjDy80//vGP8dhjjw24rrq6Gnv27MnocRwOKxwO26DrY5Yc8T4hV7b2MdsC8ubcO995T4yd6JY7zX/SIXdYBwCbRV65ajPLK0wj2g3R5VjpOP1LetR3SIzlSqtaAfT6A2Jsb1ubPJ7SQu14bDZ5vKUV8obxZZrYYZ9+CkDr+3K8qFQu1x88rFmlHJNfy2RUjgFAQrNzgtMul8Yd1sE/H6eFwvJjAkBurlxWtwobyqvk2X8OuSDzWC699FK8+eab/z6IpmZORGPPBfmJt1qtKCmRf6MQ0dh2Qb5j2bdvH8rKyjBp0iR8/etfx+HDh8XbRiIRBAKBARciGt0MTyxz587FmjVrsHHjRqxcuRJtbW344he/iN7e9FOwGxoa4PF4UpeKigqjh0REnzHDE0tdXR2++tWvYubMmaitrcWf//xn+P1+/PGPf0x7++XLl6Onpyd1aW/Xf/FGRCPfBf9W1ev1YurUqdi/f3/auMPhgMMhf/NNRKPPBU8sfX19OHDgAL7xjW9kdD+XqwiuNJuCH/XLK433D/Fp58MPdosxs6bsmdBsRB/q1W++bdGUlEMR+fskf68c69VstH7wyEfa8WS55HJ99eRq+Y6a8vf//G2zGJtQVaUdz9TqqWKsoCD9KlsAcDjl18uTq/9FZY7LDbyDEflDvG4j9ZBfXm2dSMiN0QHA6ZLLxn0B+XFzNSuxHU6L9pjRqPye7hdW5Mdiw7gp/A9+8AM0NTXh4MGDePfdd3HLLbfAYrHgjjvuMPpQRDRCGf6J5ciRI7jjjjvQ3d2NcePG4ZprrkFzczPGjRuiTwgRjRmGJ5Z169YZ/ZBENMpwrRARGY6JhYgMx8RCRIZjYiEiw43YZcfevAK43FmDrt/fvle8T+dBefk+ALht8jyEnqDc+b4vcFSMmZL6JfH+XnnOiT8kz2+wpmkZcVphcZEYc+XIcz8AYPzEWWKsQjP3oe2fW8WYxSTPcYkl9Mv3jx2XdyOYMWOaGLtoyiQxVqFpfQAA2VddLsZ27dGsawvLO0REbJq2CdBvUp9U8vwQn69DjNk1E0s9efJ75BR5/lUolL69yLDOYyEiYmIhIsMxsRCR4ZhYiMhwTCxEZDgmFiIy3IgtN7e1tcDhHFze23MgfV8XAOjoPKB9zISmxUGOZ3Bp+7TqKRPF2PRp07XH7Dwm7wxw6Jg8nnElxWJswmS5FUFOgb7M2HVSPqY6LpfrDx+Sy7DHNBvYT7tEOxx8eapcUg72yecuqaliq6hc/gaAD5rl0vmU6svEWPF4rxhrfm+LGPN16dut6sq44ZD8XE6elFsquLK92mMmlVweD/anf4/E4/qpA2fiJxYiMhwTCxEZjomFiAzHxEJEhmNiISLDMbEQkeFGbLn57//zNqxpOudbi+VO8pOnzdA+pkuzOfe0S6aIseqp5WIsEdZ3Q1dmuWQahLzJuNUmr6S1WLxiLBbXd6gP9p4QY56oXPaMJ5QYO3xUXhnuzP5EOx5Pbp4YmzR5ohhTmt+JIX/6LvOn7dm2U37ckPwemV57gxibMVNebR3ari83H9h/UIy53dlizOMt0DyqvjQcCMivWSSS/vyx3ExEw4qJhYgMx8RCRIZjYiEiwzGxEJHhmFiIyHAZl5u3bNmCp556Ci0tLejs7MT69etx8803p+JKKTz66KP49a9/Db/fj3nz5mHlypWYMkUu56Zz7JNuWCyDS7mXz/pf4n0cDn0T5XxNZbi0TG54fEKz4Xf7frl8CwDRpFz+NZvk8p3FKpc9E0puCo64/iVNROTyt0rIx8z2FIqx7j55xbTZLq8aB4CkksvYgCam6WGe7dQ3r55YViHGnBb5mGbIjdFnTJdXnHu9Xu14/jv0VzHm65TLwuOLysRYwqTfiN6WZirHaYFA+vL4qVXYcjP7M2X8iSUYDGLWrFlYsWJF2viTTz6Jn//851i1ahW2bduGrKws1NbWIhzWP1EiGjsy/sRSV1eHurq6tDGlFJ599lk8/PDDuOmmmwAAL7zwAoqLi/HKK6/g9ttvP7/REtGoYOh3LG1tbfD5fFi4cGHqOo/Hg7lz52Lr1vTNdSKRCAKBwIALEY1uhiYWn88HACguHtj9rLi4OBX7tIaGBng8ntSlokL++5eIRodhrwotX74cPT09qUt7e/twD4mIzpOhiaWkpAQA0NXVNeD6rq6uVOzTHA4HcnNzB1yIaHQzdHVzVVUVSkpK0NjYiMsuuwzAqdLVtm3bcO+992b0WK6sPFitg4dn01Qg/X55j2UAcOR7xVh/XK5f6gparrwc/TGTJjkYlsvNSvPKhGPy6l2nS/+SmjX7LCfN8n2zC+TSpl3JJXeLS169DADKLs8BSJrk52lKyGVss0V/DmxZdjHmypZj8Yg87aD7ky4xVpClnwZx01dqxdj2fx4UY32aRtvhyDHtMSPC/swA4M3xpr0+Go1pH/NMGSeWvr4+7N//7075bW1t2LlzJ/Lz81FZWYn7778fP/vZzzBlyhRUVVXhRz/6EcrKygbMdSGisS3jxLJ9+3Zcd911qf8vW7YMALBkyRKsWbMGDz74IILBIO655x74/X5cc8012LhxI5xptvIgorEp48Qyf/58KM1sSZPJhJ/85Cf4yU9+cl4DI6LRa9irQkQ09jCxEJHhmFiIyHBMLERkuBHbpb+kYgJstsFzCkxmOReGw/p1Rl0B+enavXJbgFhcnttgstm0xwz1yUvtY0p+Llar3G4hbpFj7iEmGBYV+MWYOiHPbYhqNi43JeXn4XK5tOMxa1pZJJV8zERCngNktg2xc4JFHm9fUJ6rYkrKc50cmvdl4Jg8xwUAXO58MXZtzUwx1nrgkBjb/WH6JTSn9QXkVhd2YYcI3eb1n8ZPLERkOCYWIjIcEwsRGY6JhYgMx8RCRIZjYiEiw43YcrMyWaBMg8uGupJXf69cKgQAh6b02RuQl/5Hw3JX/P6A/pg2TdeEnCy5bDwuTy5B5ubLLQPGefXl3YTVI8ZCDvncnpggt02IJDrlA2paPABAIq5p46BpOZEwy6Vf0xDlZm++3MohmZDHm9C89zwe+bzbTbqdCAB/r1+MqZg8XeGyael7HAGAN0d+bwHAhg3yzgDHuo6nvZ6bwhPRsGJiISLDMbEQkeGYWIjIcEwsRGQ4JhYiMtyILTcjHgXSVButSbk86RmirW6FRy5fXjzJK8aynXIp0WLS5+ZgwC/Gwv09YsyVJXdEr54il6IrJpRrx2O2TRBjfX6//LilpfJ42uTdEXLz9S9Kfp68GttqlVeVJzUVXKWvNsOZ5RZj8bBcUjZrjmnTrbqHPF0BAAoKs8VYX79c/g765RXM48fpdwa4+cZFYuyV199Mez1XNxPRsGJiISLDMbEQkeGYWIjIcEwsRGQ4JhYiMlzG5eYtW7bgqaeeQktLCzo7O7F+/foB+zLfeeed+N3vfjfgPrW1tdi4cWNGx5k35zK40pR5J10yS7xPxyefaB9zfJlcpp06ZbIYKxlXJMYsSrN8GUCvZuVqRLPy12SWHzc7S17dnJ2tL+9a7HLp3KYp5YeC8ibjX5gul7AnTp2oHU8sKZfVleb3Xjwplz6VRf+aWGzy2z4WlmvKSU251WyVx2py6scDzX0jMfn8WC1yI/dE1K895DhNifuaL16Z9vpQOIL1//229nFPy/gTSzAYxKxZs7BixQrxNjfccAM6OztTlz/84Q+ZHoaIRrGMP7HU1dWhrq5OexuHw4GSErlXBBGNbRfkO5bNmzejqKgI1dXVuPfee9Hd3S3eNhKJIBAIDLgQ0ehmeGK54YYb8MILL6CxsRFPPPEEmpqaUFdXJ24w1dDQAI/Hk7pUVFQYPSQi+owZvlbo9ttvT/17xowZmDlzJiZPnozNmzdjwYIFg26/fPlyLFu2LPX/QCDA5EI0yl3wcvOkSZNQWFiI/fv3p407HA7k5uYOuBDR6HbBVzcfOXIE3d3dKNWsjk3n8kunIitNWfXSy+Vyc2i6XDIGgCyPnLTk1syAMsnlQrOm5AcA+Vnyl9iarZu1GT+p2UM4PtQKVE35MhKR926efFGlGHPZ5fJ3KCiv4AYAZda8BU1yTGkaVCeVvnl1QvN6JjXLpqMh+fwkkvI5MFv15Waz5tXu7ZanJBxqaxdj8665XHvM/pjcBN4tlMdNQ0ytOFPGiaWvr2/Ap4+2tjbs3LkT+fn5yM/Px2OPPYbFixejpKQEBw4cwIMPPoiLLroItbW1mR6KiEapjBPL9u3bcd1116X+f/r7kSVLlmDlypXYtWsXfve738Hv96OsrAyLFi3CT3/6Uzgc+u0IiGjsyDixzJ8/H0rzUfONN944rwER0ejHtUJEZDgmFiIyHBMLERmOiYWIDDdiu/Q7s7LgSjOPJdspV5ey3EM8Havcvl3X9d2km8eiiZ16XHnOSTKmiWm+IDdpOsLHtTNyAE03BijNjgPZXrnlRDwhHzORHKJlvmbjdwV5E3Kz7okk9K9JwirPPVLQvBE0G9ibkvJYHUOcA1tCPu9ZYfm+qkueV3Ps4y7tMcur5d0cjpuFjeh12xR8+qZnfUsiorPExEJEhmNiISLDMbEQkeGYWIjIcEwsRGS4EVtuzs7NQ0724E7iStOmoD8ilwMBQEXkzbkjmvsG+4JiLBrTHzMSkdsUxONymTamaW8Q0xyzX7OJOAD0B+Xl8nFNO4acfI8c83jFmDenUDsep13e+D2h2TUAJk3HfOhbR+TkyDsZdB+VjxkOCWVYAMlknhgzQX6OAJBMyO/L3Bx5esWEymIxFuqX37MAoDS7HHhy0reAsFmGmDpwBn5iISLDMbEQkeGYWIjIcEwsRGQ4JhYiMhwTCxEZbsSWm1//8yY4nYPLggnb38T7nDypX9HZ13NcjOkWbupK0V1d+mMmNMum8zWbzecVFogxh0V+2YIn/Nrx7N33kRgL9Mnl1IoqeeN3i02eApCbIz8PAKiqkrv/l1fIOxxUTRovxvId+tXNOU55vEnNTg7QlFtjCbl8a9Fs+g4AFs14iyfK5XpnrlyKjil5tTUAWDQV8Pz89OfA4dDvSHEmfmIhIsMxsRCR4ZhYiMhwTCxEZDgmFiIyHBMLERkuo3JzQ0MDXn75ZezZswculwtXX301nnjiCVRXV6duEw6H8f3vfx/r1q1DJBJBbW0tfvWrX6G4WF6Jmc7bf9sGa5qmx97y6jS3PkUl5HIpAOx4920xNqFcbi5cWCCXTD854tMeM65psuzO94qxqFleadx1RN4MfMGcGu14Lpt5qRjrj4TFmNkmv1XaDh8SY3v3HdCO5/3dO8SY1zN4dftpi//zFjE279Kp2mPalfz7tLy0QoxFNeVmk6a591Cb1Md0TcOtmibdXnmVtkvTcB0AkhZ5CoVUVLZmkC0y+sTS1NSE+vp6NDc3Y9OmTYjFYli0aBGCwX8v0X7ggQfw2muv4aWXXkJTUxM6Ojpw6623ZnIYIhrlMvrEsnHjxgH/X7NmDYqKitDS0oJrr70WPT09eP7557F27Vpcf/31AIDVq1dj2rRpaG5uxlVXXWXcyIloxDqv71h6enoAAPn5p/acaWlpQSwWw8KFC1O3ufjii1FZWYmtW7emfYxIJIJAIDDgQkSj2zknlmQyifvvvx/z5s3D9OnTAQA+nw92ux1er3fAbYuLi+Hzpf8uoqGhAR6PJ3WpqJD/xiWi0eGcE0t9fT12796NdevWndcAli9fjp6entSlvV3+YpKIRodzWoS4dOlSbNiwAVu2bEH5GdWUkpISRKNR+P3+AZ9aurq6UFKSfkGZw+GAwyEvpiKi0SejTyxKKSxduhTr16/HW2+9haqqqgHx2bNnw2azobGxMXVda2srDh8+jJoafRmUiMaOjD6x1NfXY+3atXj11VeRk5OT+t7E4/HA5XLB4/HgrrvuwrJly5Cfn4/c3Fzcd999qKmpybgidPN/3gGXyz3oekfRFPE+/b36OSX73v+nGCstkb/bMWvmBLicmmX2AKJJeePuqdPl55JXKrdU6C+UO8L/R91CMQYA7hyXGAtq5rFo9m5HXLPxfTguPyYAHD16QowdausQY263fN59R7q1xzz4wT4xZg7L4/3Yd1SMzVl0hRibMLFMOx5dywWzU9PfwCbPcTFpuvCfuoF8X7sp/etpt539pvAZJZaVK1cCAObPnz/g+tWrV+POO+8EADzzzDMwm81YvHjxgAlyRPT5kVFiUUPMIAQAp9OJFStWYMWKFec8KCIa3bhWiIgMx8RCRIZjYiEiwzGxEJHhRmyXfofNDId9cN7bu2e3eJ9Aj77crPvyORaVl5H3aTaFN5n0HeGdms7msX55g/aeY/JYuw7Ls5P/8sZftOM52as5Zl+PGMvJlcu7nrx8MZal6SQPAEeOyCXlokK5E78zVy7H/+11/Tk4sW+XGEtEY2Jsv0/ekeFIUD6vU6bJ0woAwJM7eFpFKpbnEWMut9w2wZOl76hvc8otINzu9K9ZNC5PK/g0fmIhIsMxsRCR4ZhYiMhwTCxEZDgmFiIyHBMLERluxJabe090IR4avBL3rVdfF+/T7juifUxzTF5pvGuXpiWmpqQcjw+1ilQu0W3a8JYYs9vkMu1ll39BjEXtOdrhBCL9Yuzjw/Lq3e5ueTP5aFh+jh2+g9rxtB2UH/eKy2eLsf9Tv0yMvdecvg3qafEeefVzIBIRYyHIUwA+3i5PAfhbS6d2PFlWucRts8tlYYumj1HOEOXm8gkTxdhNi29Pe31//9mvbuYnFiIyHBMLERmOiYWIDMfEQkSGY2IhIsMxsRCR4UZsubmkqBhud9ag66dMrEpz61MU9KsvrZqN1i2akrLZIudfldSX4OzOwc8hxSavTi0rk1f2zq+tFWM5bnmlLAB4nHIj7g93y83G9+6XN3cvGT9RjIU1G7ADgCVNw/TTdu/dI8Y+3LtXjLknTtMes6NDPgd5XjlWZJcbW7uz5SblJ3yHtOPp/mS/GDt2XF5RHU5oVuvrup8D6PTLP/pXL0h/31BI/5hn4icWIjIcEwsRGY6JhYgMx8RCRIZjYiEiwzGxEJHhMio3NzQ04OWXX8aePXvgcrlw9dVX44knnkB1dXXqNvPnz0dTU9OA+33nO9/BqlWrMhrYyeMnEXYNXml61dyrxftc/aUvaR/T4ZBXilo1JWXd3s1Jzb7FAGCBfMxYVN4/NxSVVyF3H2kTYyfC8kpZADhxXN4r+WNNSbnjqNyoPLtIszexQy6pA4DJLpebo3F5pfGmpnfE2ITJM7THrMjXNOk2yz8Sbs2K80hYbqb9ceAD7Xiyc+RG5Qklr573newTY4WFE7XH7I/J79u3mt5Le30sJjec/7SMPrE0NTWhvr4ezc3N2LRpE2KxGBYtWoRgcGAX+7vvvhudnZ2py5NPPpnJYYholMvoE8vGjRsH/H/NmjUoKipCS0sLrr322tT1brcbJSUlxoyQiEad8/qOpafn1D40+fkD95X5/e9/j8LCQkyfPh3Lly9Hf7/8sT4SiSAQCAy4ENHods5T+pPJJO6//37MmzcP06dPT13/ta99DRMmTEBZWRl27dqFH/7wh2htbcXLL7+c9nEaGhrw2GOPneswiGgEOufEUl9fj927d+OddwZ+iXbPPfek/j1jxgyUlpZiwYIFOHDgACZPnjzocZYvX45ly/7dZjAQCKCiouJch0VEI8A5JZalS5diw4YN2LJlC8rLy7W3nTt3LgBg//79aROLw+GAQ9O7k4hGn4wSi1IK9913H9avX4/NmzejqkpeaXzazp07AQClpaXnNEAiGn0ySiz19fVYu3YtXn31VeTk5MDnOzW3wePxwOVy4cCBA1i7di2+8pWvoKCgALt27cIDDzyAa6+9FjNnzsxoYG63A27X4E8y3YGweJ8du1q0j1lUJC+JLy4qFGOxmDw35ORJv/aYCMvjtSblxx1fJc8NqciTO/F/slffET7YJ88NKSqWK3nuAq8YszjleRj9Ifn5A0BpaaUY83XIuy4c75Y3sC8tC4oxADApud1AX0QzD8gqf7KOJeU5SQ6XpnUGAIemZUe0+5h8R7Pcib9Y08oCAKIReU6KdHo0p22QjBLLypUrAZyaBHem1atX484774Tdbsebb76JZ599FsFgEBUVFVi8eDEefvjhTA5DRKNcxn8K6VRUVAyadUtEnz9cK0REhmNiISLDMbEQkeGYWIjIcCO2S7/DmoTDNnhpdyTsF+/z7ruN2sdUMbn0meuWu6zHYvLS9XBI3mgeAKya3D1hojzDePpVl4ixyZVyKdrfLpdoAcB38rgYs6cp76eOWSCXoo8dk5fvz6ieLsYA4NIZ1WJs3f99QYxZIXfMjwX1Je5oVI6ruFw2hlN+H+g2aJ9YNUk7nqPtrXLQLLfdcGXJx5w2bar2mOF++TWrKC1Ke30koj+vZ+InFiIyHBMLERmOiYWIDMfEQkSGY2IhIsMxsRCR4UZsubk/HALSLfrUdMyvrfsP7WMmo/KqV4umpJxMyB3NlUUuBwKAxSqXRZ1Zcod6n18uY/f65Q3RT4Tk5wEAJqfcNb9158dirHurvMp2UpVcMr7yoina8UQ1q59ddrmcqjQrzodaUW22yG973V7qoaT8PrAm5PM+oVxfbg73dYuxS3LlldHvtewQYx2HNCVsAKGg/LOg+k+mvT56obr0ExGdDSYWIjIcEwsRGY6JhYgMx8RCRIZjYiEiw43YcnNWlg1u9+BSrUfTHTNnnH5FZyQiN5J2anKs3SSXjJVLXhUNAI40z+G0ZFheYdrbK+8IaXHLzauLJnu145nsllc372uTN4WHSS6r29xyWfiTzsPa8RQUyg3OdbFoSC6XRiJyo20ACGpWP0c0q35jEXlHT6tTnjpQXDZOO55DnV1irOuw/JqE++TneeCDndpjFhTIY1J5+emv12wk/2n8xEJEhmNiISLDMbEQkeGYWIjIcEwsRGQ4JhYiMhwTCxEZLuO9m1euXImDBw8CAC699FI88sgjqKurAwCEw2F8//vfx7p16xCJRFBbW4tf/epXKC4uznhg/X37gUSaJf5JORfaTNnax+zqkuv++z48KMacVnmuit3j1R6zULMRfVmhR4xZNe0hCjwFYkzT4QEAEA6lXxIPAEVF8vyY8WXp5zYAQKfPJ8b27v1IO56J0Soxppt31Nsrv5b9/fK8EAAI9MhzhHTzWBJRuZWFxSG3N/hgd6F2PLoN2ouK5J+d8TPlHRCKxul/5grHybsuOIXnEr5QXfrLy8vx+OOPo6WlBdu3b8f111+Pm266CR988AEA4IEHHsBrr72Gl156CU1NTejo6MCtt96aySGIaAzI6BPLjTfeOOD///Vf/4WVK1eiubkZ5eXleP7557F27Vpcf/31AIDVq1dj2rRpaG5uxlVXXZX2MSORyIDfTIGA/NuEiEaHc/6OJZFIYN26dQgGg6ipqUFLSwtisRgWLlyYus3FF1+MyspKbN26VXychoYGeDye1KWiQt7Ei4hGh4wTy/vvv4/s7Gw4HA5897vfxfr163HJJZfA5/PBbrfD6/UOuH1xcTF8mr/Bly9fjp6entSlvb094ydBRCNLxosQq6ursXPnTvT09OBPf/oTlixZgqampnMegMPhgEOzPSURjT4ZJxa73Y6LLroIADB79mz8/e9/x3PPPYfbbrsN0WgUfr9/wKeWrq4ulJTI30AT0dhz3m0TkskkIpEIZs+eDZvNhsbGRixevBgA0NraisOHD6Ompibjx1XRCJJpVuqbNX+9WWP6jvm5aTaZP62lWf7U5euSWw2YbPpPW3PmzBZj19RcIcZ6euRy6q5/bBNjwbC+JLj3sPyn5sf/mkaQTqhfbhmglNza3pmrbxkQCPSKsV7NBvbBgFw21zTaBwBYLfItPDly+4OyKrk0nldQKsaKyvS/WMsunyHG8jVd+u2aHSIsQ+weoWuDAZX+Z8xqtekf88zbnvUtcer7kLq6OlRWVqK3txdr167F5s2b8cYbb8Dj8eCuu+7CsmXLkJ+fj9zcXNx3332oqakRK0JENDZllFiOHj2Kb37zm+js7ITH48HMmTPxxhtv4Mtf/jIA4JlnnoHZbMbixYsHTJAjos+XjBLL888/r407nU6sWLECK1asOK9BEdHoxrVCRGQ4JhYiMtyIa6at1Klu2aFw+gVoMU0ujCv9N+Fh4TEBIKHZlzep5A7eJqVf9ReLy3v6hjWL7CKahWmRqByLRuU9jQEgrhlPUnMOlC6mqQolkwnteJKQ4/pjarqqD0F3V905SCTkserOa2yIPY91iy3DEfk9nTR/tlWh04sQz+bcm9T5vEIXwJEjRzitn2gEa29vR3l5ufY2Iy6xJJNJdHR0ICcnByaTCYFAABUVFWhvb0durrys//OK50eP52doZ3uOlFLo7e1FWVkZzJq2HsAI/FPIbDanzYa5ubl8Y2jw/Ojx/AztbM6RxyP3EDoTv7wlIsMxsRCR4UZ8YnE4HHj00Ue5AlrA86PH8zO0C3GORtyXt0Q0+o34TyxENPowsRCR4ZhYiMhwTCxEZDgmFiIy3IhOLCtWrMDEiRPhdDoxd+5cvPfee8M9pGGzZcsW3HjjjSgrK4PJZMIrr7wyIK6UwiOPPILS0lK4XC4sXLgQ+/btG57BDoOGhgZceeWVyMnJQVFREW6++Wa0trYOuE04HEZ9fT0KCgqQnZ2NxYsXo6tLv2viWLFy5UrMnDkzNbu2pqYGf/nLX1Jxo8/NiE0sL774IpYtW4ZHH30U//jHPzBr1izU1tbi6NGjwz20YREMBjFr1iyxidaTTz6Jn//851i1ahW2bduGrKws1NbWIjxED9yxoqmpCfX19WhubsamTZsQi8WwaNEiBIPB1G0+zzt1fua7mKoRas6cOaq+vj71/0QiocrKylRDQ8MwjmpkAKDWr1+f+n8ymVQlJSXqqaeeSl3n9/uVw+FQf/jDH4ZhhMPv6NGjCoBqampSSp06HzabTb300kup23z00UcKgNq6detwDXNY5eXlqd/85jcX5NyMyE8s0WgULS0tA3ZVNJvNWLhwoXZXxc+rtrY2+Hy+AefL4/Fg7ty5n9vzdXqXg/z8U5vZn+tOnWORUbuY6oy41c0AcPz4cSQSCRQXFw+4vri4GHv27BmmUY1cp3eaTHe+dLtQjlXJZBL3338/5s2bh+nTpwPAOe/UOZa8//77qKmpQTgcRnZ2dmoX0507dxp+bkZkYiE6H/X19di9ezfeeeed4R7KiGL0LqY6I/JPocLCQlgslkHfSnNXxfROnxOeL2Dp0qXYsGED3n777QF9fUpKSlI7dZ7p83SOTu9iOnv2bDQ0NGDWrFl47rnnLsi5GZGJxW63Y/bs2WhsbExdl0wm0djYeE67Ko51VVVVKCkpGXC+AoEAtm3b9rk5X0opLF26FOvXr8dbb72Fqk/tWnjmTp2nnc9OnWNBul1MTzvvc2PQF8yGW7dunXI4HGrNmjXqww8/VPfcc4/yer3K5/MN99CGRW9vr9qxY4fasWOHAqCefvpptWPHDnXo0CGllFKPP/648nq96tVXX1W7du1SN910k6qqqlKhUGiYR/7ZuPfee5XH41GbN29WnZ2dqUt/f3/qNt/97ndVZWWleuutt9T27dtVTU2NqqmpGcZRf3Yeeugh1dTUpNra2tSuXbvUQw89pEwmk/rrX/+qlDL+3IzYxKKUUr/4xS9UZWWlstvtas6cOaq5uXm4hzRs3n77bQVg0GXJkiVKqVMl5x/96EequLhYORwOtWDBAtXa2jq8g/4MpTs3ANTq1atTtwmFQup73/ueysvLU263W91yyy2qs7Nz+Ab9Gfr2t7+tJkyYoOx2uxo3bpxasGBBKqkoZfy5YT8WIjLciPyOhYhGNyYWIjIcEwsRGY6JhYgMx8RCRIZjYiEiwzGxEJHhmFiIyHBMLERkOCYWIjIcEwsRGe7/A324PSYrT4wsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 Dataset\n",
    "original_train_dataset = datasets.CIFAR10(root=data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "original_test_dataset = datasets.CIFAR10(root=data_dir, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "plt.imshow(original_train_dataset.data[1]) # represnting a sample data from CIFAR-10\n",
    "plt.show()\n",
    "\n",
    "print(torch.is_tensor(original_train_dataset[1][0]))  # This will print True if the data is indeed a PyTorch tensor\n",
    "print(original_train_dataset[1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(original_train_dataset.data,dtype='float32')\n",
    "x_test = np.array(original_test_dataset.data,dtype='float32')\n",
    "\n",
    "\n",
    "x_test = torch.tensor(x_test)\n",
    "x_test = x_test.permute(0,3,1,2)\n",
    "x_test.to(device)\n",
    "\n",
    "\n",
    "# Reshape y_train and y_test to 2D arrays\n",
    "y_train = np.array(original_train_dataset.targets)\n",
    "y_test = np.array(original_test_dataset.targets)\n",
    "\n",
    "y_test = torch.tensor(y_test)\n",
    "y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(x, y, batch_size):\n",
    "    n = len(y)\n",
    "    steps = n // batch_size\n",
    "    if n % batch_size != 0:\n",
    "        steps += 1\n",
    "    x_batches = np.array_split(x,steps)\n",
    "    y_batches = np.array_split(y,steps)\n",
    "    return x_batches, y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([16, 3, 5, 5])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([16, 16, 5, 5])\n",
      "conv2.bias torch.Size([16])\n",
      "conv3.weight torch.Size([32, 16, 5, 5])\n",
      "conv3.bias torch.Size([32])\n",
      "conv4.weight torch.Size([32, 32, 5, 5])\n",
      "conv4.bias torch.Size([32])\n",
      "conv5.weight torch.Size([64, 32, 5, 5])\n",
      "conv5.bias torch.Size([64])\n",
      "fc1.weight torch.Size([128, 4096])\n",
      "fc1.bias torch.Size([128])\n",
      "fc2.weight torch.Size([128, 128])\n",
      "fc2.bias torch.Size([128])\n",
      "fc3.weight torch.Size([10, 128])\n",
      "fc3.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding='same')\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, padding='same')\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding='same')\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding='same')\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same')\n",
    "        \n",
    "        # Max pooling layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=64*8*8, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        for name, param in self.named_parameters():\n",
    "            print(name, param.shape)\n",
    "            if name == \"conv1.weight\" or name == \"conv2.weight\" or name == \"conv3.weight\" or name == \"conv4.weight\" or name == \"conv5.weight\" or name == \"fc1.weight\" or name == \"fc2.weight\" or name == \"fc3.weight\":\n",
    "                nn.init.normal_(param,std=0.05)\n",
    "            if name == \"conv1.bias\" or name == \"conv2.bias\" or name == \"conv3.bias\" or name == \"conv4.bias\" or name == \"conv5.bias\" or name == \"fc1.bias\" or name == \"fc2.bias\" or name == \"fc3.bias\":\n",
    "                nn.init.zeros_(param)\n",
    "        self.to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU activation\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv5(x))\n",
    "        \n",
    "        # Flatten the output for fully connected layers\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        \n",
    "        # Fully connected layers with ReLU activation\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        \n",
    "        # Output layer with softmax activation\n",
    "        #x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "model = MyCNN(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kv2HXF9gIQ-Q"
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 256\n",
    "x_train_batches, y_train_batches = make_batches(x_train, y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7L-wvColI2fW"
   },
   "outputs": [],
   "source": [
    "N_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "colab_type": "code",
    "id": "T6q_InsGI-ad",
    "outputId": "e465ca79-d6dc-4442-fe67-94a3cc3a6b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t last batch loss: 1.8863343000411987\n",
      "epoch: 1 \t last batch loss: 1.6850991249084473\n",
      "epoch: 2 \t last batch loss: 1.5256953239440918\n",
      "epoch: 3 \t last batch loss: 1.4202570915222168\n",
      "epoch: 4 \t last batch loss: 1.3495240211486816\n",
      "epoch: 5 \t last batch loss: 1.2969039678573608\n",
      "epoch: 6 \t last batch loss: 1.2422821521759033\n",
      "epoch: 7 \t last batch loss: 1.181040644645691\n",
      "epoch: 8 \t last batch loss: 1.1344681978225708\n",
      "epoch: 9 \t last batch loss: 1.0838072299957275\n",
      "epoch: 10 \t last batch loss: 1.0469635725021362\n",
      "epoch: 11 \t last batch loss: 1.0168917179107666\n",
      "epoch: 12 \t last batch loss: 0.974344789981842\n",
      "epoch: 13 \t last batch loss: 0.932620644569397\n",
      "epoch: 14 \t last batch loss: 0.8892673254013062\n",
      "epoch: 15 \t last batch loss: 0.8581683039665222\n",
      "epoch: 16 \t last batch loss: 0.827208399772644\n",
      "epoch: 17 \t last batch loss: 0.7967416048049927\n",
      "epoch: 18 \t last batch loss: 0.780257523059845\n",
      "epoch: 19 \t last batch loss: 0.7680070400238037\n",
      "epoch: 20 \t last batch loss: 0.7337794899940491\n",
      "epoch: 21 \t last batch loss: 0.7243111729621887\n",
      "epoch: 22 \t last batch loss: 0.7077741026878357\n",
      "epoch: 23 \t last batch loss: 0.6945227384567261\n",
      "epoch: 24 \t last batch loss: 0.680840790271759\n",
      "epoch: 25 \t last batch loss: 0.6513049602508545\n",
      "epoch: 26 \t last batch loss: 0.6309817433357239\n",
      "epoch: 27 \t last batch loss: 0.6200099587440491\n",
      "epoch: 28 \t last batch loss: 0.6291572451591492\n",
      "epoch: 29 \t last batch loss: 0.6153217554092407\n",
      "epoch: 30 \t last batch loss: 0.5775450468063354\n",
      "epoch: 31 \t last batch loss: 0.5627506971359253\n",
      "epoch: 32 \t last batch loss: 0.5535898208618164\n",
      "epoch: 33 \t last batch loss: 0.5323798656463623\n",
      "epoch: 34 \t last batch loss: 0.5039652585983276\n",
      "epoch: 35 \t last batch loss: 0.46665287017822266\n",
      "epoch: 36 \t last batch loss: 0.4350334703922272\n",
      "epoch: 37 \t last batch loss: 0.4661821126937866\n",
      "epoch: 38 \t last batch loss: 0.4624587297439575\n",
      "epoch: 39 \t last batch loss: 0.40176740288734436\n",
      "epoch: 40 \t last batch loss: 0.37376827001571655\n",
      "epoch: 41 \t last batch loss: 0.3709808886051178\n",
      "epoch: 42 \t last batch loss: 0.4016288220882416\n",
      "epoch: 43 \t last batch loss: 0.45753926038742065\n",
      "epoch: 44 \t last batch loss: 0.498216450214386\n",
      "epoch: 45 \t last batch loss: 0.38809385895729065\n",
      "epoch: 46 \t last batch loss: 0.34724175930023193\n",
      "epoch: 47 \t last batch loss: 0.31794190406799316\n",
      "epoch: 48 \t last batch loss: 0.29312828183174133\n",
      "epoch: 49 \t last batch loss: 0.34917861223220825\n",
      "epoch: 50 \t last batch loss: 0.3278420567512512\n",
      "epoch: 51 \t last batch loss: 0.3004411458969116\n",
      "epoch: 52 \t last batch loss: 0.26746779680252075\n",
      "epoch: 53 \t last batch loss: 0.23863574862480164\n",
      "epoch: 54 \t last batch loss: 0.22258752584457397\n",
      "epoch: 55 \t last batch loss: 0.2129819393157959\n",
      "epoch: 56 \t last batch loss: 0.20996317267417908\n",
      "epoch: 57 \t last batch loss: 0.24949389696121216\n",
      "epoch: 58 \t last batch loss: 0.23071551322937012\n",
      "epoch: 59 \t last batch loss: 0.17635902762413025\n",
      "epoch: 60 \t last batch loss: 0.1765422523021698\n",
      "epoch: 61 \t last batch loss: 0.1681678593158722\n",
      "epoch: 62 \t last batch loss: 0.21750640869140625\n",
      "epoch: 63 \t last batch loss: 0.2208763062953949\n",
      "epoch: 64 \t last batch loss: 0.2399672269821167\n",
      "epoch: 65 \t last batch loss: 0.269249826669693\n",
      "epoch: 66 \t last batch loss: 0.24750986695289612\n",
      "epoch: 67 \t last batch loss: 0.21166400611400604\n",
      "epoch: 68 \t last batch loss: 0.17372271418571472\n",
      "epoch: 69 \t last batch loss: 0.17605336010456085\n",
      "epoch: 70 \t last batch loss: 0.17775818705558777\n",
      "epoch: 71 \t last batch loss: 0.1449878066778183\n",
      "epoch: 72 \t last batch loss: 0.13578465580940247\n",
      "epoch: 73 \t last batch loss: 0.12650808691978455\n",
      "epoch: 74 \t last batch loss: 0.12263914197683334\n",
      "epoch: 75 \t last batch loss: 0.13882550597190857\n",
      "epoch: 76 \t last batch loss: 0.13759194314479828\n",
      "epoch: 77 \t last batch loss: 0.16048851609230042\n",
      "epoch: 78 \t last batch loss: 0.13661831617355347\n",
      "epoch: 79 \t last batch loss: 0.09894690662622452\n",
      "epoch: 80 \t last batch loss: 0.1126573383808136\n",
      "epoch: 81 \t last batch loss: 0.11841493844985962\n",
      "epoch: 82 \t last batch loss: 0.1398567110300064\n",
      "epoch: 83 \t last batch loss: 0.07848308980464935\n",
      "epoch: 84 \t last batch loss: 0.09629075974225998\n",
      "epoch: 85 \t last batch loss: 0.08323550224304199\n",
      "epoch: 86 \t last batch loss: 0.09521131217479706\n",
      "epoch: 87 \t last batch loss: 0.057710856199264526\n",
      "epoch: 88 \t last batch loss: 0.064635269343853\n",
      "epoch: 89 \t last batch loss: 0.06724969297647476\n",
      "epoch: 90 \t last batch loss: 0.08082811534404755\n",
      "epoch: 91 \t last batch loss: 0.08260847628116608\n",
      "epoch: 92 \t last batch loss: 0.0809735357761383\n",
      "epoch: 93 \t last batch loss: 0.06512758880853653\n",
      "epoch: 94 \t last batch loss: 0.15119916200637817\n",
      "epoch: 95 \t last batch loss: 0.10930188000202179\n",
      "epoch: 96 \t last batch loss: 0.06628522276878357\n",
      "epoch: 97 \t last batch loss: 0.060727499425411224\n",
      "epoch: 98 \t last batch loss: 0.07644134759902954\n",
      "epoch: 99 \t last batch loss: 0.12825123965740204\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "for epoch in range(N_EPOCH):\n",
    "    for i in range(len(x_train_batches)):\n",
    "        x = torch.tensor(x_train_batches[i])\n",
    "        y = torch.tensor(y_train_batches[i])\n",
    "\n",
    "        x = x.permute(0,3,1,2)\n",
    "\n",
    "        x.to(device)\n",
    "        y.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # test\n",
    "        # zero gradients\n",
    "        # TODO\n",
    "        if i % 10 == 0:\n",
    "            y_test_pred = model(x_test)\n",
    "            test_loss = criterion(y_test_pred, y_test)\n",
    "            loss.append(test_loss.item())\n",
    "    \n",
    "    print(\"epoch: {} \\t last batch loss: {} \\t last batch loss: {}\".format(epoch, loss.item(),test_loss.item()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
